{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "262ee4f1cc793d5cc0302d24cbc64461",
     "grade": false,
     "grade_id": "cell-aa820d6aaf4304db",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "version = \"REPLACE_PACKAGE_VERSION\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a2887f2fd08b4a5ea1b21dcff5acfdda",
     "grade": false,
     "grade_id": "cell-24e63ee011a83003",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "# Assignment 2 Part 1: Time Series Patterns (50 pts)\n",
    "\n",
    "In this assignment, we're going to practise some techniques that are useful for discerning patterns in a time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f69af28b9f8a0a049a1d78263219255",
     "grade": false,
     "grade_id": "cell-0153dc3ed86e1f61",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "167459fd8a4aff55ca38072dc3aa0b3f",
     "grade": false,
     "grade_id": "cell-d63bebc6fef0f0d1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 1: Load Data (5 pts)\n",
    "\n",
    "At the time of writing this assignment, August 2020, COVID-19 is still the most topical public-health crisis globally with nearly 300,000 new cases reported worldwide every day. **The number of daily new cases worldwide** is a time series that arises naturally from this topical event, and in this assignment we'll apply some of the techniques we learned in class to this very time series to discern any patterns it may contain. \n",
    "\n",
    "You are provided with a csv file, `assets/time_series_covid19_confirmed_global.csv`, which is part of the [Johns Hopkins University CSSE COVID-19 dataset](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series). As the name suggests, it contains the number of *cumulative* confirmed cases globally as of certain dates. However, we are interested in the number of *new* cases worldwide every day. \n",
    "\n",
    "Create a function called `load_data` that reads in the csv file and produces a `pd.Series` that looks like: \n",
    "\n",
    "```\n",
    "2020-01-23        99.0\n",
    "2020-01-24       287.0\n",
    "2020-01-25       493.0\n",
    "2020-01-26       684.0\n",
    "2020-01-27       809.0\n",
    "                ...   \n",
    "2020-08-17    209672.0\n",
    "2020-08-18    255096.0\n",
    "2020-08-19    274346.0\n",
    "2020-08-20    267183.0\n",
    "2020-08-21    270751.0\n",
    "Length: 212, dtype: float64\n",
    "```\n",
    "\n",
    "where\n",
    "* the index of the series is a `pd.DatetimeIndex`; \n",
    "* the values of the series are daily *new* cases worldwide; and\n",
    "* the series doesn't contain any `NaN` values. \n",
    "\n",
    "\n",
    "**This function should return a `pd.Series` of length 212, whose index is a `pd.DatetimeIndex`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56db97165aadda80b1d07ba073369486",
     "grade": false,
     "grade_id": "cell-993d3b939f534f62",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    daily_new_cases = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return daily_new_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57a8b49d1fb8f013d00de4913b6b6693",
     "grade": true,
     "grade_id": "cell-b4092afc6b697987",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = load_data()\n",
    "\n",
    "assert isinstance(stu_ans, pd.Series), \"Q1: Your function should return a pd.Series. \"\n",
    "assert len(stu_ans) == 212, \"Q1: The length of the series returned is incorrect. \"\n",
    "assert isinstance(stu_ans.index, pd.DatetimeIndex), \"Q1: The index of your series must be a pd.DatetimeIndex. \"\n",
    "assert ((\"2020-01-23\" <= stu_ans.index) & (stu_ans.index <= \"2020-08-21\")).all(), \"Q1: The index of your series contains an incorrect time range. \"\n",
    "assert not stu_ans.isna().any(), \"Q1: Your series contains NaN values. \"\n",
    "assert np.issubdtype(stu_ans.dtype, np.floating), \"Q1: Your series should have a float dtype. \"\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot and see the time series\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(load_data())\n",
    "ax.set_xlabel(\"Day\")\n",
    "ax.set_ylabel(\"# Cases\")\n",
    "ax.set_title(\"Daily New COVID-19 Cases Worldwide\")\n",
    "\n",
    "del fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83a1ab628192cf434c16b23cb205b022",
     "grade": false,
     "grade_id": "cell-902e515e7633ecbd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 2: Perform a Seasonal Decomposition (5 pts)\n",
    "\n",
    "With the time series ready, let's first perform a seasonal decomposition using tools from the `statsmodels` library to get a sense of what the possible patterns are hidden in the data. Complete the function below that takes a time series and an argument `model`, which indicates whether an additive or multiplicative seasonal decomposition should be performed, and that returns a `DecomposeResult` as produced by the `seasonal_decompose` function from the `statsmodels` library. \n",
    "\n",
    "**This function should return a `statsmodels.tsa.seasonal.DecomposeResult`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75af59b9493d7ffdea4ed1ef9289e3b6",
     "grade": false,
     "grade_id": "cell-7b3c4bc030367baf",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose, DecomposeResult\n",
    "\n",
    "def sea_decomp(ser, model=\"additive\"):\n",
    "    \"\"\"\n",
    "    Takes in a series and a \"model\" parameter indicating which seasonal decomp to perform\n",
    "    \"\"\"\n",
    "    result = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f7190926aa0e3f5f23488e62b6f29a6",
     "grade": true,
     "grade_id": "cell-7bf5710aeb564606",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ser = load_data()\n",
    "stu_ans = sea_decomp(stu_ser, model=\"additive\")\n",
    "\n",
    "assert isinstance(stu_ans, DecomposeResult), \"Q2: Your function should return a DecomposeResult. \"\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "\n",
    "del stu_ser, stu_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot and see the seasonal decomposition\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(10, 6), sharex=True)\n",
    "res = sea_decomp(load_data(), model=\"additive\")\n",
    "\n",
    "axes[0].set_title(\"Additive Seasonal Decomposition\")\n",
    "axes[0].plot(res.observed)\n",
    "axes[0].set_ylabel(\"Observed\")\n",
    "\n",
    "axes[1].plot(res.trend)\n",
    "axes[1].set_ylabel(\"Trend\")\n",
    "\n",
    "axes[2].plot(res.seasonal)\n",
    "axes[2].set_ylabel(\"Seasonal\")\n",
    "\n",
    "axes[3].plot(res.resid)\n",
    "axes[3].set_ylabel(\"Residual\")\n",
    "\n",
    "axes[3].set_xlabel(\"Day\")\n",
    "fig.suptitle(\"Daily New COVID-19 Cases Worldwide\", x=0.513, y=0.95)\n",
    "\n",
    "del fig, axes, res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38027658c40b041264da6398ab48e347",
     "grade": false,
     "grade_id": "cell-4b22a356806c732d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 3: Fit a Trend Curve (15 pts)\n",
    "\n",
    "The plot above suggests that there is a non-linear trend hidden in the time series. One approach to discover such a trend is to fit a regression model to the time series and ask the regression model to make predictions at each timestamp. When connected, these chronological predictions form a \"trend curve\". In the problem, we will explore how to fit a trend curve to our time series. \n",
    "\n",
    "Complete the function below that fits an `n`-th order polynomial to the input time series and that returns the predictions as a `np.ndarray` of the same length. An $n$-th order polynomial regression model assumes that each dependent variable $y_{i}$ is an $n$-th order polynomial function of the corresponding independent variable $x_{i}$:\n",
    "\n",
    "\\begin{equation*}\n",
    "y_{i} = c_{0} + c_{1}x_{i} + c_{2}x_{i}^{2} + \\cdots + c_{n}x_{i}^{n}\n",
    "\\end{equation*}\n",
    "\n",
    "Now, the most interesting and important question to think about is, \"**what are $x_{i}$'s and $y_{i}$'s in the problem?**\". The $y_{i}$'s are the daily new cases worldwide at timestamps $x_{i}$'s, but **how should we represent the timestamps $x_{i}$'s in such a regression model?** There are many choices you may explore. In the function below, you are already given the code for training a polynomial regression model, but you have to figure out what `train_X` ($x_{i}$'s) and `train_y` ($y_{i}$'s) are. Since it's possible that everyone has a different design, this question is graded on the $R^{2}$ score of your predictions. **For a $10$-th order polynomial regression model, at least one choice of $x_{i}$'s leads to an $R^{2}$ score $\\geq 0.95$.** \n",
    "\n",
    "**This function should return a `np.ndarray` of shape `(len(ser), )`, which represents the predictions of your polynomial regression model on the input time series. The predictions form the \"trend curve\" we are looking for.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ffec0f52212b4e7fa9496dfba5caf1ca",
     "grade": false,
     "grade_id": "cell-69afe3a5c5318d23",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def fit_trend(ser, n):\n",
    "    \"\"\"\n",
    "    Takes a series and fits an n-th order polynomial to the series. \n",
    "    Returns the predictions. \n",
    "    \"\"\"\n",
    "    \n",
    "    trend_curve = None\n",
    "    train_X, train_y = None, None # xi's and yi's\n",
    "\n",
    "    # Create train_X and train_y\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Fit a polynomial regression model - code given to you\n",
    "    train_X = PolynomialFeatures(n).fit_transform(train_X.reshape(-1, 1))\n",
    "    lin_reg = LinearRegression().fit(train_X, train_y.reshape(-1))\n",
    "    \n",
    "    # Make predictions to create the trend curve\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return trend_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c707d340042410fe615736f2cbd23d4",
     "grade": true,
     "grade_id": "cell-9868250e72c14c0e",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ser = load_data()\n",
    "stu_ans = fit_trend(stu_ser, 10)\n",
    "\n",
    "assert isinstance(stu_ans, np.ndarray), \"Q3: Your function should return a np.ndarray. \"\n",
    "assert stu_ans.shape == (len(stu_ser), ), \"Q3: The shape of your np.ndarray is not correct. \"\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "\n",
    "del stu_ser, stu_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot and see your regression line\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ser = load_data()\n",
    "preds = fit_trend(ser, 10)\n",
    "ax.plot(ser.index, ser.values, label=\"Original\")\n",
    "ax.plot(ser.index, preds, label=\"Fitted trend curve\")\n",
    "ax.set_xlabel(\"Day\")\n",
    "ax.set_ylabel(\"# Cases\")\n",
    "ax.set_title(\"Daily New COVID-19 Cases Worldwide\")\n",
    "ax.legend()\n",
    "\n",
    "del fig, ax, ser, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "62f30bc41589da8aea97852e701d05a3",
     "grade": false,
     "grade_id": "cell-221cc22c9e3cad75",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "It's worth mentioning that the `seaborn` library provides a function [`regplot`](https://seaborn.pydata.org/generated/seaborn.regplot.html) that can plot both the data and the regression line in a few lines of code, thus saving you the trouble of fitting a regression model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e983aa3006f854d0e5335d126a01f21",
     "grade": false,
     "grade_id": "cell-caf5a40a85230775",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 4: Calculate Weighted Moving Average (WMA) (15 pts)\n",
    "\n",
    "The regression method seems to give a fairly accurate description of the trend hidden in the time series. In this problem and the next, we will explore an alternative method for discovering trends that is based on moving averages.\n",
    "\n",
    "Recall from the lectures that a Weighted Moving Average (WMA) method applies the following transformation to each data point $x_{j}$:\n",
    "\n",
    "\\begin{align}\n",
    "x_{j}^{\\prime} &=\n",
    "\\frac{w_{k}x_{j} + w_{k - 1}x_{j - 1} + \\cdots + w_{1}x_{j - k + 1}}{w_{k} + w_{k - 1} + \\cdots + w_{1}} & \\text{if } j > k \\\\ \\\\\n",
    "x_{j}^{\\prime} &= \\frac{w_{k}x_{j} + w_{k - 1}x_{j - 1} + \\cdots + w_{k - j + 1}x_{1}}{w_{k} + w_{k - 1} + \\cdots + w_{k - j + 1}} & \\text{if } j \\leq k\n",
    "\\end{align}\n",
    "\n",
    "for a window of size $k$. Complete the function below that calculates the WMA for an input time series. \n",
    "\n",
    "**This function should return a `np.ndarray` of shape `(len(ser), )` that represents the WMA values for the input time series.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d514da767be3f5342e143a4236e0119",
     "grade": false,
     "grade_id": "cell-e02c1a2ff068f6c2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calc_wma(ser, wd_size, weights=1):\n",
    "    \"\"\"\n",
    "    Takes in a series and calculates the WMA with a window size of wd_size\n",
    "    \"\"\"\n",
    "    wma = None\n",
    "    if isinstance(weights, int):\n",
    "        weights = np.full(wd_size, weights, dtype=float)\n",
    "\n",
    "    assert len(weights) == wd_size, \"Q4: The size of the weights must be the same as the window size. \"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return wma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "705772650ece7ed0d469a6815552932c",
     "grade": true,
     "grade_id": "cell-5273144a89ada0d1",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "wd_size = 7\n",
    "weights = np.arange(1, wd_size + 1).astype(float) # linear weighting\n",
    "stu_ser = load_data()\n",
    "stu_ans = calc_wma(stu_ser, wd_size, weights)\n",
    "\n",
    "assert isinstance(stu_ans, np.ndarray), \"Q4: Your function should return a np.ndarray. \"\n",
    "assert stu_ans.shape == (len(stu_ser), ), \"Q4: The np.ndarray returned is of an incorrect shape. \"\n",
    "assert np.issubdtype(stu_ans.dtype, np.floating), \"Q4: Your np.ndarray should have a float dtype. \"\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "\n",
    "del wd_size, weights, stu_ser, stu_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot and see your WMA\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "wd_size = 7\n",
    "weights = np.arange(1, wd_size + 1)\n",
    "ser = load_data()\n",
    "wma = calc_wma(ser, wd_size, weights=weights)\n",
    "\n",
    "ax.plot(ser.index, ser.values, label=\"Original\")\n",
    "ax.plot(ser.index, wma, label=\"WMA\")\n",
    "ax.set_xlabel(\"Day\")\n",
    "ax.set_ylabel(\"# Cases\")\n",
    "ax.set_title(\"Daily New COVID-19 Cases Worldwide\")\n",
    "ax.legend()\n",
    "\n",
    "del fig, ax, wd_size, weights, ser, wma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94dd8a192f49e94bfa59a13099d012ee",
     "grade": false,
     "grade_id": "cell-96f2af8cec541faa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 5: Calculate \"Time\" Exponential Moving Average (EMA) (10 pts)\n",
    "\n",
    "WMA usually works well if each data point is sampled at regular time intervals (which is the case for our time series). \"Time\" Exponential Moving Average (EMA), on the other hand, works well on both regular and irregular time series. Let's now explore how to apply EMA to our time series.\n",
    "\n",
    "Recall from the lectures that a \"time\" EMA method applies the following transformation to each data point $x_{j}$:\n",
    "\n",
    "\\begin{equation*}\n",
    "x_{j}^{\\prime} = \\frac{\\sum_{i = 1}^{j}\\exp\\left[-\\lambda\\left(t_{j} - t_{i}\\right)\\right]x_{i}}{\\sum_{i = 1}^{j}\\exp\\left[-\\lambda\\left(t_{j} - t_{i}\\right)\\right]}\n",
    "\\end{equation*}\n",
    "\n",
    "where $0 \\leq \\lambda \\leq 1$ is the \"decay rate\". Also note that, when $\\lambda = 0$, this is equivalent to a cumulative moving average (CMA). Complete the function below that calculates the \"time\" EMA for an input time series, **assuming the time intervals are days**.\n",
    "\n",
    "**This function should return a `np.ndarray` of shape `(len(ser), )`, which represents the \"time\" EMA for the input time series.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2bf9060bc55a69dd55c1f9cea25ccd5",
     "grade": false,
     "grade_id": "cell-a2bbae3ec5a0d3d6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calc_time_ema(ser, lmbd=0.0):\n",
    "    \"\"\"\n",
    "    Takes in a series and calculates EMA with the lambda provided\n",
    "    \"\"\"\n",
    "    \n",
    "    time_ema = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return time_ema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22fa1a8fd3d5c36a761abff65b52a091",
     "grade": true,
     "grade_id": "cell-2735b9190219eef7",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ser = load_data()\n",
    "\n",
    "# Sanity checks for a trivial case - CMA\n",
    "stu_ans = calc_time_ema(stu_ser, lmbd=0.0)\n",
    "\n",
    "assert isinstance(stu_ans, np.ndarray), \"Q5: Your function should return a np.ndarray. \"\n",
    "assert stu_ans.shape == (len(stu_ser), ), \"Q5: The np.ndarray returned is of an incorrect shape. \"\n",
    "assert np.issubdtype(stu_ans.dtype, np.floating), \"Q5: Your np.ndarray should have a float dtype. \"\n",
    "assert np.isclose(stu_ans, np.cumsum(stu_ser) / np.arange(1, len(stu_ser) + 1)).all(), \"Q5: When lmbd = 0 your function should calculate CMA. \"\n",
    "\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "\n",
    "del stu_ser, stu_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot and see your time EMA\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ser = load_data()\n",
    "ema = calc_time_ema(ser, lmbd=0.5)\n",
    "\n",
    "ax.plot(ser.index, ser.to_numpy(), label=\"Original\")\n",
    "ax.plot(ser.index, ema, label=\"Time EMA\")\n",
    "ax.set_xlabel(\"Day\")\n",
    "ax.set_ylabel(\"# Cases\")\n",
    "ax.set_title(\"Daily New COVID-19 Cases Worldwide\")\n",
    "ax.legend()\n",
    "\n",
    "del fig, ax, ser, ema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc572d7b4d5992379b1a59e5f602fe42",
     "grade": false,
     "grade_id": "cell-6cbf848ff9ca8948",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The [`SimpleExpSmoothing`](https://www.statsmodels.org/stable/examples/notebooks/generated/exponential_smoothing.html#) class from the `statsmodels` library is a handy tool for EMA. See an example below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import SimpleExpSmoothing\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ser = load_data()\n",
    "ema = SimpleExpSmoothing(ser, initialization_method=None).fit(smoothing_level=0.5, optimized=False)\n",
    "\n",
    "ax.plot(ser, label=\"Original\")\n",
    "ax.plot(ema.fittedvalues, label=\"EMA\")\n",
    "ax.set_xlabel(\"Day\")\n",
    "ax.set_ylabel(\"# Cases\")\n",
    "ax.set_title(\"Daily New COVID-19 Cases Worldwide\")\n",
    "ax.legend()\n",
    "\n",
    "del ser, ema, fig, ax"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_data_mining_ii_v1_assignment2_part1"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
