{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "262ee4f1cc793d5cc0302d24cbc64461",
     "grade": false,
     "grade_id": "cell-aa820d6aaf4304db",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "version = \"REPLACE_PACKAGE_VERSION\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b53426112a02c62eb9cde9a1158d8307",
     "grade": false,
     "grade_id": "cell-24e63ee011a83003",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "# Assignment 2 Part 2: Time Series Similarities (50 pts)\n",
    "\n",
    "In this assignment, we're going to explore several techniques for measuring similarity between two time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f69af28b9f8a0a049a1d78263219255",
     "grade": false,
     "grade_id": "cell-0153dc3ed86e1f61",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "688a26e636a078ceb6cb81eac96c9c38",
     "grade": false,
     "grade_id": "cell-d63bebc6fef0f0d1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 1: Load data (5 pts)\n",
    "\n",
    "We will continue to explore the data we used in Part 1, `assets/time_series_covid19_confirmed_global.csv` from the [Johns Hopkins University CSSE COVID-19 dataset](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series). This time, we are interested in the number of daily new cases **exclusively from the top 5 countries that have the most cumulative cases as of August 21, 2020**. \n",
    "\n",
    "Create a function called `load_data` that reads in the csv file and produces a `pd.DataFrame` that looks like: \n",
    "\n",
    "| | ? | ? | ? | ? | ? |\n",
    "|-: | -: | -: | -: | -: | -: |\n",
    "|**2020-01-23**|0.0|0.0|0.0|0.0|0.0|\n",
    "|**2020-01-24**|1.0|0.0|0.0|0.0|0.0|\n",
    "|**2020-01-25**|0.0|0.0|0.0|0.0|0.0|\n",
    "|**2020-01-26**|3.0|0.0|0.0|0.0|0.0|\n",
    "|**2020-01-27**|0.0|0.0|0.0|0.0|0.0|\n",
    "|**...**|...|...|...|...|...|\n",
    "|**2020-08-17**|35112.0|19373.0|55018.0|4839.0|2541.0|\n",
    "|**2020-08-18**|44091.0|47784.0|64572.0|4718.0|2258.0|\n",
    "|**2020-08-19**|47408.0|49298.0|69672.0|4790.0|3916.0|\n",
    "|**2020-08-20**|44023.0|45323.0|68900.0|4767.0|3880.0|\n",
    "|**2020-08-21**|48693.0|30355.0|69876.0|4838.0|3398.0|\n",
    "\n",
    "where\n",
    "* the index of the DataFrame is a `pd.DatetimeIndex`; \n",
    "* the column names \"?\" are the top 5 countries with the most cumulative cases as of August 21, 2020, sorted in descending order from left to right;\n",
    "* the values of the DataFrame are daily new cases; and\n",
    "* the DataFrame doesn't contain any `NaN` values. \n",
    "\n",
    "\n",
    "**This function should return a `pd.DataFrame` of shape `(212, 5)`, whose index is a `pd.DatetimeIndex` and whose column labels are the top 5 countries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56db97165aadda80b1d07ba073369486",
     "grade": false,
     "grade_id": "cell-993d3b939f534f62",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    daily_new_cases = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return daily_new_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a445ffe64d5ae9698f721a5a0472896d",
     "grade": true,
     "grade_id": "cell-e1d58c28b254af33",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = load_data()\n",
    "\n",
    "assert isinstance(stu_ans, pd.DataFrame), \"Q1: Your function should return a pd.DataFrame. \"\n",
    "assert stu_ans.shape == (212, 5), \"Q1: The shape of your pd.DataFrame returned is incorrect. \"\n",
    "assert isinstance(stu_ans.index, pd.DatetimeIndex), \"Q1: The index of your pd.DataFrame must be a pd.DatetimeIndex. \"\n",
    "assert ((\"2020-01-23\" <= stu_ans.index) & (stu_ans.index <= \"2020-08-21\")).all(), \"Q1: The index of your pd.DataFrame contains an incorrect time range. \"\n",
    "assert not stu_ans.isna().any(axis=None), \"Q1: Your pd.DataFrame contains NaN values. \"\n",
    "assert stu_ans.dtypes.apply(lambda x: np.issubdtype(x, np.floating)).all(), \"Q1: All columns of your pd.DataFrame should have a float dtype. \"\n",
    "\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot and see the time series\n",
    "axes = load_data().plot(figsize=(10, 6), title=\"Daily New COVID-19 Cases\", ylabel=\"# Cases\")\n",
    "\n",
    "del axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f3e66beb0d22fc9295314db820997d4",
     "grade": false,
     "grade_id": "cell-902e515e7633ecbd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 2: Extract Seasonal Components (5 pts)\n",
    "\n",
    "Recall from the lectures that an additive Seasonal Decomposition decomposes a time series into the following components:\n",
    "\n",
    "\\begin{equation*}\n",
    "Y(t) = T(t) + S(t) + R(t)\n",
    "\\end{equation*}\n",
    "\n",
    "where $T(t)$ represents trends, $S(t)$ represents seasonal patterns and $R(t)$ represents residuals. In the rest of the assignment, we will work with the seasonal component $S(t)$ to understand the similarities among the seasonal patterns of the five time series we have, so let's write a function that extracts this very seasonal component. \n",
    "\n",
    "Complete the function below that accepts a `pd.DataFrame` and returns another `pd.DataFrame` of the same shape that looks like:\n",
    "\n",
    "| | ? | ? | ? | ? | ? |\n",
    "|-: | -: | -: | -: | -: | -: |\n",
    "|**2020-01-23**|2431.761670|3380.626554|441.179428|-54.886371|322.986535|\n",
    "|**2020-01-24**|3446.796153|3457.641332|621.396176|23.689984|362.434811|\n",
    "|**2020-01-25**|578.564626|586.665963|594.066127|55.034811|391.346141|\n",
    "|**2020-01-26**|-2728.454422|-6031.950950|46.655454|137.908703|76.880131|\n",
    "|**2020-01-27**|-3293.854422|-7144.674760|-1234.673118|1.842036|-507.496059|\n",
    "|**...**|...|...|...|...|...|\n",
    "|**2020-08-17**|-3293.854422|-7144.674760|-1234.673118|1.842036|-507.496059|\n",
    "|**2020-08-18**|-719.521088|1549.577621|-544.749308|-28.929392|-662.877011|\n",
    "|**2020-08-19**|284.707483|4202.114239|76.125240|-134.659770|16.725452|\n",
    "|**2020-08-20**|2431.761670|3380.626554|441.179428|-54.886371|322.986535|\n",
    "|**2020-08-21**|3446.796153|3457.641332|621.396176|23.689984|362.434811|\n",
    "\n",
    "where\n",
    "* the index of the DataFrame is a `pd.DatetimeIndex`; \n",
    "* the column names \"?\" are the top 5 countries with the most cumulative cases as of August 21, 2020, sorted in descending order from left to right;\n",
    "* the values of the DataFrame are the seasonal components $S(t)$ as returned by the `seasonal_decompose` function from `statsmodels`; and\n",
    "* the DataFrame doesn't contain any `NaN` values. \n",
    "\n",
    "\n",
    "**This function should return a `pd.DataFrame` of shape `(len(df), 5)`, whose index is a `pd.DatetimeIndex` and whose column labels are the top 5 countries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2810bc11279252a475746a90b3c9e84",
     "grade": false,
     "grade_id": "cell-7b3c4bc030367baf",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "def sea_decomp(df, model=\"additive\"):\n",
    "    \"\"\"\n",
    "    Takes in a DataFrame and extracts the seasonal components\n",
    "    \"\"\"\n",
    "    sea_df = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return sea_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ac6cac64e5a7de0ff508f92a093c2ac",
     "grade": true,
     "grade_id": "cell-622db2c0fcbd02a7",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_df = load_data()\n",
    "stu_ans = sea_decomp(stu_df, \"additive\")\n",
    "\n",
    "assert isinstance(stu_ans, pd.DataFrame), \"Q2: Your function should return a pd.DataFrame. \"\n",
    "assert stu_ans.shape == (len(stu_df), 5), \"Q2: The shape of your pd.DataFrame returned is incorrect. \"\n",
    "assert isinstance(stu_ans.index, pd.DatetimeIndex), \"Q2: The index of your pd.DataFrame must be a pd.DatetimeIndex. \"\n",
    "assert ((\"2020-01-23\" <= stu_ans.index) & (stu_ans.index <= \"2020-08-21\")).all(), \"Q2: The index of your pd.DataFrame contains an incorrect time range. \"\n",
    "assert not stu_ans.isna().any(axis=None), \"Q2: Your pd.DataFrame contains NaN values. \"\n",
    "assert stu_ans.dtypes.apply(lambda x: np.issubdtype(x, np.floating)).all(), \"Q2: All columns of your pd.DataFrame should have a float dtype. \"\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "\n",
    "del stu_df, stu_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot and see the seasonal components\n",
    "\n",
    "df = load_data()\n",
    "axes = sea_decomp(df).plot(figsize=(10, 6), title=\"Seasonal Component of Daily New COVID-19 Cases\")\n",
    "\n",
    "del df, axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bbc97ed4ec58cc8cc641edbe865740d9",
     "grade": false,
     "grade_id": "cell-4b22a356806c732d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 3: Calculate Euclidean Distance (10 pts)\n",
    "\n",
    "Now, we may start to ask questions like, \"which country in the top 5 countries are the most similar to Country A in terms of seasonal patterns?\". In addition to the seasonal components that reflect seasonal patterns, we also need a measure of similarity between two time series in order to answer questions like this. One of such measures is the good old Euclidean Distance. \n",
    "\n",
    "Recall that the Euclidean Distance between two vectors $x$ and $y$ is the length of the vector $x - y$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathrm{EucDist}(x, y) = \\left\\lVert x - y \\right\\rVert_{2} = \\sqrt{\\left(x - y\\right)^{T}\\left(x - y\\right)} = \\sqrt{\\sum_{i = 1}^{n}\\left(x_{i} - y_{i}\\right)^{2}}\n",
    "\\end{equation*}\n",
    "\n",
    "Complete the function below that accepts a `pd.DataFrame`, whose columns are time series for each country, and that returns all pairwise Euclidean Distance among these time series, similar to the following:\n",
    "\n",
    "| | ? | ? | ? | ? | ? |\n",
    "|-: | -: | -: | -: | -: | -: |\n",
    "|**?**|0.000000|233760.757213||||\n",
    "|**?**|233760.757213|0.000000||||\n",
    "|**?**|||0.000000|||\n",
    "|**?**||||0.000000||\n",
    "|**?**|||||0.000000|\n",
    "\n",
    "where\n",
    "* the index and the column names \"?\" are the top 5 countries with the most cumulative cases as of August 21, 2020, sorted in descending order from top to bottom and from left to right; and\n",
    "* the values of the DataFrame are pairwise Euclidean Distance, for example, `233760.757213` is the Euclidean Distance between the time series of the Rank 1 country and the Rank 2 country\n",
    "\n",
    "**This function should return a `pd.DataFrame` of shape `(5, 5)`, whose index and column labels are the top 5 countries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03ba771127c0c9ac6ea96e42ced7ba94",
     "grade": false,
     "grade_id": "cell-69afe3a5c5318d23",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calc_euclidean_dist(df):\n",
    "    \"\"\"\n",
    "    Takes in a DataFrame and computes all pairwise Euclidean Distance\n",
    "    \"\"\"\n",
    "    euclidean_dist_df = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return euclidean_dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ae8a37cb3e24dd45c777fb4572d8642",
     "grade": true,
     "grade_id": "cell-3b4b3af2bb715740",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_df = load_data()\n",
    "stu_ans = calc_euclidean_dist(stu_df)\n",
    "\n",
    "assert isinstance(stu_ans, pd.DataFrame), \"Q3: Your function should return a pd.DataFrame. \"\n",
    "assert stu_ans.shape == (5, 5), \"Q3: The shape of your pd.DataFrame is not correct. \"\n",
    "assert (stu_ans.index == stu_ans.columns).all(), \"Q3: Your pd.DataFrame should have the same index and column labels. \"\n",
    "assert stu_ans.dtypes.apply(lambda x: np.issubdtype(x, np.floating)).all(), \"Q3: All columns of your pd.DataFrame should have a float dtype. \"\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "\n",
    "del stu_df, stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df17b811a2d2b0995d724539f7083fe7",
     "grade": false,
     "grade_id": "cell-73e000b692c2e085",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now let's calculate the pairwise Euclidean Distance between seasonal patterns. What can you say about the similarities among these seasonal patterns? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's show the pairwise Euclidean Distance matrix\n",
    "\n",
    "df = load_data()\n",
    "calc_euclidean_dist(sea_decomp(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69d99839aaa085df0e465865b18e3a16",
     "grade": false,
     "grade_id": "cell-caf5a40a85230775",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 4: Calculate Cosine Similarity (10 pts)\n",
    "\n",
    "Another commonly used similarity measure is the Cosine Similarity. Recall that the Cosine Similarity between two vectors $x$ and $y$ is the cosine of the angle between $x$ and $y$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathrm{CosSim}(x, y) = \\frac{x^{T}y}{\\left\\lVert x \\right\\rVert_{2} \\left\\lVert y \\right\\rVert_{2}} = \\left(\\frac{x}{\\left\\lVert x \\right\\rVert_{2}}\\right)^{T}\\left(\\frac{y}{\\left\\lVert y \\right\\rVert_{2}}\\right)\n",
    "\\end{equation*}\n",
    "\n",
    "Complete the function below that accepts a `pd.DataFrame`, whose columns are the time series for each country, and that returns all pairwise Cosine Similarity among these time series, similar to the following:\n",
    "\n",
    "| | ? | ? | ? | ? | ? |\n",
    "|-: | -: | -: | -: | -: | -: |\n",
    "|**?**|1.000000\t|0.898664||||\n",
    "|**?**|0.898664|1.000000||||\n",
    "|**?**|||1.000000|||\n",
    "|**?**||||1.000000||\n",
    "|**?**|||||1.000000|\n",
    "\n",
    "where\n",
    "* the index and the column names \"?\" are the top 5 countries with the most cumulative cases as of August 21, 2020, sorted in descending order from top to bottom and from left to right; and\n",
    "* the values of the DataFrame are pairwise Cosine Similarity, for example, `0.898664` is the Cosine Similarity between the time series of the Rank 1 country and the Rank 2 country\n",
    "\n",
    "**This function should return a `pd.DataFrame` of shape `(5, 5)`, whose index and column labels are the top 5 countries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3dbc2030ca322375d10d36e0c2c1abbf",
     "grade": false,
     "grade_id": "cell-e02c1a2ff068f6c2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calc_cos_sim(df):\n",
    "    \"\"\"\n",
    "    Takes in a DataFrame and computes all pairwise Cosine Similarity\n",
    "    \"\"\"\n",
    "    cos_sim_df = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return cos_sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "923be34f21c6a8787392806c25f08639",
     "grade": true,
     "grade_id": "cell-5273144a89ada0d1",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_df = load_data()\n",
    "stu_ans = calc_cos_sim(stu_df)\n",
    "\n",
    "assert isinstance(stu_ans, pd.DataFrame), \"Q4: Your function should return a pd.DataFrame. \"\n",
    "assert stu_ans.shape == (5, 5), \"Q4: The shape of your pd.DataFrame is not correct. \"\n",
    "assert (stu_ans.index == stu_ans.columns).all(), \"Q4: Your pd.DataFrame should have the same index and column labels. \"\n",
    "assert stu_ans.dtypes.apply(lambda x: np.issubdtype(x, np.floating)).all(), \"Q4: All columns of your pd.DataFrame should have a float dtype. \"\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "\n",
    "del stu_df, stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f5e516b832918de4cc82a7e1cdf911b",
     "grade": false,
     "grade_id": "cell-7ab11837a0d057c3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now let's calculate the pairwise Cosine Similarity between seasonal patterns. What can you say about the similarities among these seasonal patterns? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's show the pairwise Cosine Similarity matrix\n",
    "\n",
    "df = load_data()\n",
    "calc_cos_sim(sea_decomp(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56c8e9512bc725989214bc6ad7e382d3",
     "grade": false,
     "grade_id": "cell-96f2af8cec541faa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 5: Calculate Dynamic Time Warping (DTW) Cost (20 pts)\n",
    "\n",
    "Last but not least, the cost of aligning two time series can also be used as a similarity measure. Two time series are more similar if it incurs less cost to align them. One of the commonly used alignment costs is the Dynamic Time Warping (DTW) cost, which we will explore in this problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fcf235611895b4eda23fb4081f468baa",
     "grade": false,
     "grade_id": "cell-e1326792e287c1ed",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 5a (10 pts)\n",
    "\n",
    "Recall from the lectures that the DTW cost is defined by the following recursive relations:\n",
    "\n",
    "\\begin{align}\n",
    "&\\mathrm{DTW}(1, 1)  = d(x_{1}, y_{1}) \\\\\n",
    "&\\mathrm{DTW}(i, j)  = d(x_{i}, y_{j}) + \\min \\begin{cases}\n",
    "\\mathrm{DTW}(i, j - 1) & \\text{Repeat } x_{i} \\\\\n",
    "\\mathrm{DTW}(i - 1, j) & \\text{Repeat } y_{j} \\\\\n",
    "\\mathrm{DTW}(i - 1, j - 1) & \\text{Both proceed}\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "where we define $d(x_{i}, y_{j}) = (x_{i} - y_{j})^{2}$ as in the lectures. With reference to the demo of the DTW algorithm in the lecture slides, implement the function below that computes the DTW cost for two time series. **We don't take the square root of the results just yet, until later when we compare the DTW costs with the Euclidean Distance.**\n",
    "\n",
    "**This function should EITHER return a `np.ndarray` of shape `(len(y), len(x))` which represents the DTW cost matrix, OR a single `float` that represents the overall DTW cost, depending whether the parameter `ret_matrix=True`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "529196ff82b6ddd1e978367bfc70d4c7",
     "grade": false,
     "grade_id": "cell-a2bbae3ec5a0d3d6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calc_pairwise_dtw_cost(x, y, ret_matrix=False):\n",
    "    \"\"\"\n",
    "    Takes in two series. If ret_matrix=True, returns the full DTW cost matrix; \n",
    "    otherwise, returns only the overall DTW cost\n",
    "    \"\"\"\n",
    "    \n",
    "    cost_matrix = np.zeros((len(y), len(x)))\n",
    "    dtw_cost = None\n",
    "    \n",
    "    dist_fn = lambda a, b: (a - b) ** 2  # Optional helper function \n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return cost_matrix if ret_matrix else dtw_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "046b9eaa1cd1012ffc9fcad6153fecb0",
     "grade": true,
     "grade_id": "cell-eed7512afcf54dcc",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_df = load_data()\n",
    "\n",
    "# First test with ret_matrix=False\n",
    "stu_ans = calc_pairwise_dtw_cost(stu_df.iloc[:, 0], stu_df.iloc[:, 1], ret_matrix=False)\n",
    "assert isinstance(stu_ans, float), \"Q5a: Your function should return a float with ret_matrix=False. \"\n",
    "assert np.isclose(stu_ans, 9575974038.0), \"Q5a: The DTW cost between Rank 1 and Rank 2 countries is not correct. \"\n",
    "\n",
    "# Then test with ret_matrix=True\n",
    "stu_ans = calc_pairwise_dtw_cost(stu_df.iloc[:, 0], stu_df.iloc[:, 1], ret_matrix=True)\n",
    "assert isinstance(stu_ans, np.ndarray), \"Q5a: Your function should return a np.ndarray with ret_matrix=True. \"\n",
    "assert stu_ans.shape == (len(stu_df), len(stu_df)), \"Q5a: The shape of your np.ndarray is not correct. \"\n",
    "assert np.issubdtype(stu_ans.dtype, np.floating), \"Q5a: Your np.ndarray should have a float dtype. \"\n",
    "\n",
    "# Also test with reversing the order of the inputs\n",
    "stu_ans_T = calc_pairwise_dtw_cost(stu_df.iloc[:, 1], stu_df.iloc[:, 0], ret_matrix=True)\n",
    "assert np.isclose(stu_ans.T, stu_ans_T).all(), \"Q5a: When the order of the inputs is reversed, your new cost matrix should be the old one's transpose. \"\n",
    "\n",
    "# Some hidden tests - for Rank 1 and Rank 2 countries\n",
    "\n",
    "\n",
    "del stu_df, stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f50ca25c0f222704d1fa2fc2336555ab",
     "grade": false,
     "grade_id": "cell-dfb2f246b5ec7dff",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 5b (10 pts)\n",
    "\n",
    "Now let's compute all pairwise DTW costs for our five time series. Complete the function below that accepts a `pd.DataFrame`, whose columns are the time series for each country, and that returns all pairwise DTW costs among these time series, similar to the following:\n",
    "\n",
    "| | ? | ? | ? | ? | ? |\n",
    "|-: | -: | -: | -: | -: | -: |\n",
    "|**?**|0.000000e+00\t\t|9.575974e+09||||\n",
    "|**?**|9.575974e+09|0.000000e+00\t||||\n",
    "|**?**|||0.000000e+00\t|||\n",
    "|**?**||||0.000000e+00\t||\n",
    "|**?**|||||0.000000e+00\t|\n",
    "\n",
    "where\n",
    "* the index and the column names \"?\" are the top 5 countries with the most cumulative cases as of August 21, 2020, sorted in descending order from top to bottom and from left to right; and\n",
    "* the values of the DataFrame are pairwise DTW costs, for example, `9.575974e+09` is the DTW cost between the time series of the Rank 1 country and the Rank 2 country\n",
    "\n",
    "**This function should return a `pd.DataFrame` of shape `(5, 5)`, whose index and column labels are the top 5 countries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "388c377c696dd9c76d65e3987c7be824",
     "grade": false,
     "grade_id": "cell-2baaed6642b2920b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calc_dtw_cost(df):\n",
    "    \"\"\"\n",
    "    Takes in a DataFrame and computes all pairwise DTW costs\n",
    "    \"\"\"\n",
    "    \n",
    "    dtw_cost_df = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return dtw_cost_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ebed303c5f13601983995d22b745f288",
     "grade": true,
     "grade_id": "cell-45a7c18198a43e46",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests - takes some time\n",
    "\n",
    "stu_df = load_data()\n",
    "stu_ans = calc_dtw_cost(stu_df)\n",
    "\n",
    "assert isinstance(stu_ans, pd.DataFrame), \"Q5b: Your function should return a pd.DataFrame. \"\n",
    "assert stu_ans.shape == (5, 5), \"Q5b: The shape of your pd.DataFrame is not correct. \"\n",
    "assert (stu_ans.index == stu_ans.columns).all(), \"Q5b: Your pd.DataFrame should have the same index and column labels. \"\n",
    "assert stu_ans.dtypes.apply(lambda x: np.issubdtype(x, np.floating)).all(), \"Q5b: All columns of your pd.DataFrame should have a float dtype. \"\n",
    "\n",
    "# Some hidden tests\n",
    "\n",
    "\n",
    "del stu_df, stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "faaf71ed90da82b0b552ee24fac35f08",
     "grade": false,
     "grade_id": "cell-c6361b6c65284d5d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now let's calculate the pairwise DTW costs between seasonal patterns. **Take the sqaure root so that we can compare it with the Euclidean Distance**. What can you say about the similarities among these seasonal patterns? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's show the pairwise DTW costs matrix\n",
    "\n",
    "df = load_data()\n",
    "np.sqrt(calc_dtw_cost(sea_decomp(df)))"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_data_mining_ii_v1_assignment2_part2"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
